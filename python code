#!/usr/bin/env python
# coding: utf-8

# In[1]:


import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
data=pd.read_csv(r'C:\Users\mayan\Documents\lung cancer.csv')
data.head()


# In[2]:


data.describe()


# In[3]:


data.isna()


# In[4]:


data.isna().sum()


# In[5]:


youngsmoker=data.loc[(data["AGE"]<=50)]
youngsmoker.head()


# In[6]:


ycancer=youngsmoker.loc[(youngsmoker["ALCOHOL CONSUMING"]==2)]
ycanceralcohol=ycancer.loc[(ycancer["SMOKING"]==2)]
ycas=ycanceralcohol.loc[ycanceralcohol["LUNG_CANCER"]=="YES"]
ycas.head()


# In[7]:


x_label=["Having Cancer","Not having Cancer"]
y_label=[len(ycas),len(youngsmoker)-len(ycas)]
plt.bar(x_label,y_label)


# In[8]:


eldersmoker=data.loc[(data["AGE"]>=50)]

eldersmoker.head()



# In[9]:


ecancer=eldersmoker.loc[(eldersmoker["ALCOHOL CONSUMING"]==2)]
ecanceralcohol=ecancer.loc[(ecancer["SMOKING"]==2)]
ecas=ecanceralcohol.loc[ecanceralcohol["LUNG_CANCER"]=="YES"]
ecas.head()


# In[10]:


fig = plt.figure()
ax = fig.add_axes([0,0,1,1])
ax.axis('equal')
names = ["having Cancer","Not Having Cancer"]
per = [len(ycas),len(youngsmoker)-len(ycas)]
ax.pie(per, labels = names,autopct='%1.2f%%')
plt.show()


# In[11]:


x_label=["Having Cancer","Not having Cancer"]
y_label=[len(ecas),len(eldersmoker)-len(ecas)]
plt.bar(x_label,y_label)


# In[12]:


fig = plt.figure()
ax = fig.add_axes([0,0,1,1])
ax.axis('equal')
names = ["having Cancer","Not Having Cancer"]
per = [len(ecas),len(eldersmoker)-len(ecas)]
ax.pie(per, labels = names,autopct='%1.2f%%')
plt.show()


# In[13]:


ycasa=ycanceralcohol.loc[(ycanceralcohol["PEER_PRESSURE"]==2)]
ycasac=ycasa.loc[(ycasa["LUNG_CANCER"]=="YES")]
ycasac.head()
fig = plt.figure()
ax = fig.add_axes([0,0,1,1])
ax.axis('equal')
names = ["having Cancer","Not Having Cancer"]
per = [len(ycasa),len(ycasa)-len(ycasac)]
ax.pie(per, labels = names,autopct='%1.2f%%')
plt.show()


# In[14]:


femdata=data.loc[(data['GENDER']=='F')]
femcancer=femdata.loc[(femdata['LUNG_CANCER']=='YES')]
fig = plt.figure()
ax = fig.add_axes([0,0,1,1])
ax.axis('equal')
names = ["having Cancer","Not Having Cancer"]
per = [len(femcancer),len(femdata)-len(femcancer)]
ax.pie(per, labels = names,autopct='%1.2f%%')
plt.show()

femcancer.head()


# In[15]:


mdata=data.loc[(data['GENDER']=='M')]
mcancer=mdata.loc[(mdata['LUNG_CANCER']=='YES')]
fig = plt.figure()
ax = fig.add_axes([0,0,1,1])
ax.axis('equal')
names = ["having Cancer","Not Having Cancer"]
per = [len(mcancer),len(mdata)-len(mcancer)]
ax.pie(per, labels = names,autopct='%1.2f%%')
plt.show()

femcancer.head()


# In[16]:


onlypositive=data[data['LUNG_CANCER']=='YES']
onlypositive.head()


# In[17]:


plt.figure(figsize=(20,10))
sns.histplot(onlypositive[onlypositive['GENDER']=='M']['AGE'],kde=True,color='black')
plt.title("Age vs Count for Male")


# In[18]:


plt.figure(figsize=(20,10))
sns.histplot(onlypositive[onlypositive['GENDER']=='F']['AGE'],kde=True,color='red')
plt.title("Age vs Count for female")


# In[19]:


plt.figure(figsize=(20,10))
sns.histplot(data=onlypositive,x='AGE',hue="GENDER",kde=True,multiple='stack')


# In[20]:


from sklearn.preprocessing import LabelEncoder
Label=LabelEncoder()
data['LUNG_CANCER']=Label.fit_transform(data['LUNG_CANCER'])


# In[21]:


data['GENDER']=Label.fit_transform(data['GENDER'])
data.head()


# In[22]:


from sklearn.model_selection import train_test_split as tts
X_train,X_test,y_train,y_test= tts(data.drop('LUNG_CANCER',axis=1),data['LUNG_CANCER'],test_size=0.3,random_state=101)


# In[23]:


from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report,confusion_matrix
logmodel=LogisticRegression()
logmodel.fit(X_train,y_train)
pred_log=logmodel.predict(X_test)


# In[24]:


print(confusion_matrix(y_test,pred_log))
print(classification_report(y_test,pred_log))


# In[25]:


from sklearn.svm import SVC
svm_model=SVC(C=100,gamma=0.002)
svm_model.fit(X_train,y_train)
pred_svm=svm_model.predict(X_test)


# In[26]:


print(classification_report(y_test,pred_svm))
print(confusion_matrix(y_test,pred_svm))


# In[27]:


from sklearn.ensemble import RandomForestClassifier
randf_model=RandomForestClassifier(n_estimators=100)
randf_model.fit(X_train,y_train)
pred_randf=randf=randf_model.predict(X_test)


# In[28]:


print(confusion_matrix(y_test,pred_randf))
print(classification_report(y_test,pred_randf))


# In[29]:


from sklearn.neighbors import KNeighborsClassifier
knn_model=KNeighborsClassifier(n_neighbors=3)
knn_model.fit(X_train,y_train)
pred_knn=knn_model.predict(X_test)


# In[30]:


print(confusion_matrix(y_test,pred_knn))
print(classification_report(y_test,pred_knn))


# In[31]:


error_rate=[]
for i in range(1,20):
    knn=KNeighborsClassifier(n_neighbors=i)
    knn.fit(X_train,y_train)
    pred_i=knn.predict(X_test)
    error_rate.append(np.mean(pred_i!=y_test))


# In[32]:


plt.figure(figsize=(10,6))
plt.plot(range(1,20),error_rate,color='blue',linestyle='dashed',marker='o',markerfacecolor='red',markersize=10)
plt.title('Error Rate vs. K Value')
plt.xlabel('K')
plt.ylabel('Error Rate')


# In[33]:


knn_model=KNeighborsClassifier(n_neighbors=1)
knn_model.fit(X_train,y_train)
pred_knn=knn_model.predict(X_test)
print(confusion_matrix(y_test,pred_knn))
print(classification_report(y_test,pred_knn))


# In[34]:


input_data=(0,50,2,1,2,2,1,2,2,1,2,2,1,1,1)
#input_data=(0,20,1,1,2,1,1,2,1,1,2,1,1,1,1)
#input_data=(0,45,2,1,2,1,2,1,1,1,1,2,1,1,1)
input_data_numpy_array = np.asarray(input_data)
input_data_reshape = input_data_numpy_array.reshape(1, -1)

prediction = logmodel.predict(input_data_reshape)
print(prediction)

if (prediction[0]== 0):
    print("The person doesnot have Lung Cancer")
else:
        print("The person suffers from Lung Cancer")


# In[ ]:




